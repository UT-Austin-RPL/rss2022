---
layout: paper
title: "DiPCAN: Distilling Privileged Information for Crowd-Aware Navigation"
invisible: true
---
<head>
<style>
* {
  box-sizing: border-box;
}

#myInput {
  background-position: 10px 10px;
  background-repeat: no-repeat;
  width: 100%;
  font-size: 100%;
  padding: 12px 20px 12px 40px;
  border: 1px solid #ddd;
  margin-bottom: 12px;
}

#myTable, #myTableA {
  border-collapse: collapse;
  width: 100%;
  border: 1px solid #ddd;
  font-size: 100%;
}

#myTable th, #myTable td, #myTableA th, #myTableA td {
  text-align: left;
  padding: 12px;
}

#myTable tr, #myTableA tr {
  border-bottom: 1px solid #ddd;
}

#myTable tr.header, #myTable tr:hover, #myTableA tr.header, #myTableA tr:hover {
  background-color: #f1f1f1;
}


#eventcounter1 a {
    font-size: 12px;
    color: #ffffff;
    display: block;
}

#eventcounter1 a:hover {
    text-decoration: none;
}

#eventcounter2 a {
    font-size: 12px;
    color: #ffffff;
    display: block;
}

#eventcounter2 a:hover {
    text-decoration: none;
}

</style>
</head>

<table width = "95%" style="padding-left: 15px; margin-left: auto; margin-right: 10px;">
<tr><td style = "vertical-align: top; padding-right: 25px;" rowspan="2">
<span style="color:black; font-size: 110%;"><i>
Gianluca Monaci <span style="color:gray; font-size: 85%">(NAVER LABS Europe)</span><span style="color:gray; font-size: 100%">,</span><br>
MICHEL ARACTINGI <span style="color:gray; font-size: 85%">(NAVER LABS EUROPE)</span><span style="color:gray; font-size: 100%">,</span><br>
Tomi   Silander <span style="color:gray; font-size: 85%">(Naverlabs Europe)</span>
</i></span>
</td>

<td style="text-align: right;"><a href="http://www.roboticsproceedings.org/rss18/p045.pdf"><img src="{{ site.baseurl }}/images/paper_link.png" alt="Paper Website" width = "33"  height = "40"/></a><br></td>
</tr>
<tr>
<td style="color:#777789; text-align:right; font-size: 75%; margin-right:10px;">Paper&nbsp;#045</td>
</tr>
</table>

<table width="80%" style="margin-top: 20px; margin-left: auto; margin-right: auto;">
  <tr>
    <td style="text-align:center;">Session 7. Long talks</td>
  </tr>
</table>
<br>


### Abstract
Mobile robots need to navigate in crowded environments to provide services to humans. Traditional approaches to crowd-aware navigation decouple people motion prediction from robot motion planning, leading to undesired robot behaviours. Recent deep learning-based methods integrate crowd forecasting in the planner, assuming precise tracking of the agents in the scene. To do this they require expensive LiDAR sensors and tracking algorithms that are complex and brittle. In this paper we propose a two-step approach to first learn a robot navigation policy based on privileged information about exact pedestrian locations available in simulation. A second learning step distills the knowledge acquired by the first network into an adaptation network that uses only narrow field-of-view image data from the robot camera. While the navigation policy is trained in simulation without any expert supervision such as trajectories computed by a planner, it exhibits state-of-the-art performance on a broad range of dense crowd simulations and real-world experiments.
{: style="color:gray; font-size: 120%; text-align: justified;"}


<table width="100%" style="margin-top:40px;">
<tr>
    <td style="width: 30%; text-align: center;"><a href="{{ site.baseurl }}/program/papers/044/">
<img src="{{ site.baseurl }}/images/previous_paper_icon.png"
       alt="Previous Paper" width = "142"  height = "90"/> 
</a> </td>
<td style="text-align: center;"><a href="{{ site.baseurl }}/program/papers">
<img src="{{ site.baseurl }}/images/overview_icon.png"
       alt="Paper Website" width = "142"  height = "90"/> 
</a> </td>
    <td style="width: 30%; text-align: center;"><a href="{{ site.baseurl }}/program/papers/046/">
    <img src="{{ site.baseurl }}/images/next_paper_icon.png"
        alt="Next Paper" width = "142"  height = "90"/>
    </a></td>
</tr>
</table>
