---
layout: paper
title: "FlowBot3D: Learning 3D Articulation Flow to Manipulate Articulated Objects"
invisible: true
---
<head>
<style>
* {
  box-sizing: border-box;
}

#myInput {
  background-position: 10px 10px;
  background-repeat: no-repeat;
  width: 100%;
  font-size: 100%;
  padding: 12px 20px 12px 40px;
  border: 1px solid #ddd;
  margin-bottom: 12px;
}

#myTable, #myTableA {
  border-collapse: collapse;
  width: 100%;
  border: 1px solid #ddd;
  font-size: 100%;
}

#myTable th, #myTable td, #myTableA th, #myTableA td {
  text-align: left;
  padding: 12px;
}

#myTable tr, #myTableA tr {
  border-bottom: 1px solid #ddd;
}

#myTable tr.header, #myTable tr:hover, #myTableA tr.header, #myTableA tr:hover {
  background-color: #f1f1f1;
}


#eventcounter1 a {
    font-size: 12px;
    color: #ffffff;
    display: block;
}

#eventcounter1 a:hover {
    text-decoration: none;
}

#eventcounter2 a {
    font-size: 12px;
    color: #ffffff;
    display: block;
}

#eventcounter2 a:hover {
    text-decoration: none;
}

</style>
</head>

<table width = "95%" style="padding-left: 15px; margin-left: auto; margin-right: 10px;">
<tr><td style = "vertical-align: top; padding-right: 25px;" rowspan="2">
<span style="color:black; font-size: 110%;"><i>
Benjamin Eisner<span style="color:gray; font-size: 100%">,</span><br>
Harry Zhang<span style="color:gray; font-size: 100%">,</span><br>
David Held <span style="color:gray; font-size: 85%">(Carnegie Mellon University)</span>
</i></span>
</td>

<td style="text-align: right;"><a href="http://www.roboticsproceedings.org/rss18/p018.pdf"><img src="{{ site.baseurl }}/images/paper_link.png" alt="Paper Website" width = "33"  height = "40"/></a><br></td>
</tr>
<tr>
<td style="color:#777789; text-align:right; font-size: 75%; margin-right:10px;">Paper&nbsp;#018</td>
</tr>
</table>

<table width="80%" style="margin-top: 20px; margin-left: auto; margin-right: auto;">
  <tr>
    <td style="text-align:center;">Session 3. Long talks</td>
  </tr>
</table>
<br>


### Abstract
We explore a novel method to perceive and manipulate 3D articulated objects that generalizes to enable a robot to articulate unseen classes of objects. We propose a vision-based system that learns to predict the potential motions of the parts of a variety of articulated objects to guide downstream motion planning  of the system to  articulate the objects. To predict the object motions, we train a neural network to output a dense vector field representing the point-wise motion direction of the points in the point cloud under articulation. The system then will deploy an analytical motion planning policy based on this vector field to achieve a policy that yields maximum articulation. We train the vision system entirely in simulation, and then demonstrate the capability of our system to generalize to  unseen object instances and novel categories in both simulation and the real world, deploying our policy on a Sawyer robot with no retraining. Results suggest that our system achieves state-of-the-art performance in both simulated and real-world experiments. Code, data, and supplementary materials are available at https://sites.google.com/view/articulated-flowbot-3d/home.
{: style="color:gray; font-size: 120%; text-align: justified;"}


### Links
- [Supplementary materials](http://www.roboticsproceedings.org/rss18/p018_sup.pdf)

<table width="100%" style="margin-top:40px;">
<tr>
    <td style="width: 30%; text-align: center;"><a href="{{ site.baseurl }}/program/papers/017/">
<img src="{{ site.baseurl }}/images/previous_paper_icon.png"
       alt="Previous Paper" width = "142"  height = "90"/> 
</a> </td>
<td style="text-align: center;"><a href="{{ site.baseurl }}/program/papers">
<img src="{{ site.baseurl }}/images/overview_icon.png"
       alt="Paper Website" width = "142"  height = "90"/> 
</a> </td>
    <td style="width: 30%; text-align: center;"><a href="{{ site.baseurl }}/program/papers/019/">
    <img src="{{ site.baseurl }}/images/next_paper_icon.png"
        alt="Next Paper" width = "142"  height = "90"/>
    </a></td>
</tr>
</table>
