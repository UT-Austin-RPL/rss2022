---
layout: paper
title: "FuseBot: RF-Visual Mechanical Search"
invisible: true
---
<head>
<style>
* {
  box-sizing: border-box;
}

#myInput {
  background-position: 10px 10px;
  background-repeat: no-repeat;
  width: 100%;
  font-size: 100%;
  padding: 12px 20px 12px 40px;
  border: 1px solid #ddd;
  margin-bottom: 12px;
}

#myTable, #myTableA {
  border-collapse: collapse;
  width: 100%;
  border: 1px solid #ddd;
  font-size: 100%;
}

#myTable th, #myTable td, #myTableA th, #myTableA td {
  text-align: left;
  padding: 12px;
}

#myTable tr, #myTableA tr {
  border-bottom: 1px solid #ddd;
}

#myTable tr.header, #myTable tr:hover, #myTableA tr.header, #myTableA tr:hover {
  background-color: #f1f1f1;
}


#eventcounter1 a {
    font-size: 12px;
    color: #ffffff;
    display: block;
}

#eventcounter1 a:hover {
    text-decoration: none;
}

#eventcounter2 a {
    font-size: 12px;
    color: #ffffff;
    display: block;
}

#eventcounter2 a:hover {
    text-decoration: none;
}

</style>
</head>

<table width = "95%" style="padding-left: 15px; margin-left: auto; margin-right: 10px;">
<tr><td style = "vertical-align: top; padding-right: 25px;" rowspan="2">
<span style="color:black; font-size: 110%;"><i>
Tara Boroushaki <span style="color:gray; font-size: 85%">(Massachusetts Institute of Technology)</span><span style="color:gray; font-size: 100%">,</span><br>
Laura Dodds <span style="color:gray; font-size: 85%">(Massachusetts Institute of Technology)</span><span style="color:gray; font-size: 100%">,</span><br>
Nazish Naeem <span style="color:gray; font-size: 85%">(Massachusetts Institute of Technology)</span><span style="color:gray; font-size: 100%">,</span><br>
Fadel Adib <span style="color:gray; font-size: 85%">(MIT)</span>
</i></span>
</td>

<td style="text-align: right;"><a href="http://www.roboticsproceedings.org/rss18/p067.pdf"><img src="{{ site.baseurl }}/images/paper_link.png" alt="Paper Website" width = "33"  height = "40"/></a><br></td>
</tr>
<tr>
<td style="color:#777789; text-align:right; font-size: 75%; margin-right:10px;">Paper&nbsp;#067</td>
</tr>
</table>

<table width="80%" style="margin-top: 20px; margin-left: auto; margin-right: auto;">
  <tr>
    <td style="text-align:center;">10. Short talks</td>
  </tr>
</table>
<br>


### Abstract
Mechanical search is a robotic problem where a robot needs to retrieve a target item that is partially or fully-occluded from its camera. State-of-the-art approaches for mechanical search either require an expensive search process to find the target item, or they require the item to be tagged with a radio frequency identification tag (e.g., RFID), making their approach beneficial only to tagged items in the environment.

We present FuseBot, the first robotic system for RF-Visual mechanical search that enables efficient retrieval of both RF-tagged and untagged items in a pile. Rather than requiring all target items in a pile to be RF-tagged, FuseBot leverages the mere existence of an RF-tagged item in the pile to benefit both tagged and untagged items.
Our design introduces two key innovations. The first is RF-Visual Mapping, a technique that identifies and locates RF-tagged items in a pile and uses this information to construct an RF-Visual occupancy distribution map. The second is RF-Visual Extraction, a policy formulated as an optimization problem that minimizes the number of actions required to extract the target object by accounting for the probabilistic occupancy distribution, the expected grasp quality, and the expected information gain from future actions.

We built a real-time end-to-end prototype of our system on a UR5e robotic arm with in-hand vision and RF perception modules. We conducted over 180 real-world experimental trials to evaluate FuseBot and compare its performance to a state-of-the-art vision-based system named X-Ray. Our experimental results demonstrate that FuseBot outperforms X-Ray's efficiency by more than 40% in terms of the number of actions required for successful mechanical search. Furthermore, in comparison to X-Ray's success rate of 84%, FuseBot achieves a success rate of 95% in retrieving untagged items, demonstrating for the first time that the benefits of RF perception extend beyond tagged objects in the mechanical search problem.

{: style="color:gray; font-size: 120%; text-align: justified;"}


<table width="100%" style="margin-top:40px;">
<tr>
    <td style="width: 30%; text-align: center;"><a href="{{ site.baseurl }}/program/papers/066/">
<img src="{{ site.baseurl }}/images/previous_paper_icon.png"
       alt="Previous Paper" width = "142"  height = "90"/> 
</a> </td>
<td style="text-align: center;"><a href="{{ site.baseurl }}/program/papers">
<img src="{{ site.baseurl }}/images/overview_icon.png"
       alt="Paper Website" width = "142"  height = "90"/> 
</a> </td>
    <td style="width: 30%; text-align: center;"><a href="{{ site.baseurl }}/program/papers/068/">
    <img src="{{ site.baseurl }}/images/next_paper_icon.png"
        alt="Next Paper" width = "142"  height = "90"/>
    </a></td>
'</tr>
</table>
